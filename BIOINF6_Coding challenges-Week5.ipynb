{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for float(): 0.399\t0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-d93e1876019f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0malph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maln\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for float(): 0.399\t0.01"
     ]
    }
   ],
   "source": [
    "'''Solve the Profile HMM Problem using class object'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#file='input.txt'\n",
    "file='input2.txt'\n",
    "#file='../../Downloads/dataset_11632_2.txt'\n",
    "#file='../../Downloads/rosalind_ba10e.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "th=float(lines[0])\n",
    "alph=map(str,lines[2].split('\\t'))\n",
    "aln=[list(line) for line in lines[4:]]\n",
    "print th,alph,aln\n",
    "\n",
    "\n",
    "class HMM:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    def __init__(self, threshold, alphabet, alignment):\n",
    "        self.th = threshold #e.g. 0.301\n",
    "        self.alph = alphabet #e.g. ['A', 'B', 'C', 'D', 'E']\n",
    "        self.aln = alignment #e.g.  [['E', 'B', 'A'], ['E', '-', 'D'], ['E', 'B', '-'], ['E', 'E', 'D'], ['E', 'B', 'D'], ['E', 'B', 'E'], ['E', '-', 'D'], ['E', '-', 'D']]\n",
    "        self.I = self.find_insertions()[1]\n",
    "        self.good_col = self.find_insertions()[0]\n",
    "        self.hmm = ['S','I0']+[St+str(n) for n in range(1,self.good_col+1) for St in ['M','D','I']]+['E']\n",
    "    \n",
    "    def find_insertions(self):\n",
    "        a=pd.DataFrame(self.aln)\n",
    "        I={}\n",
    "        good_col=len(a.columns)\n",
    "        M_counter=0\n",
    "        for n in range(len(a.columns)):\n",
    "            col=n\n",
    "            try:\n",
    "                if float(a[col].value_counts().to_dict()['-'])/sum(a[col].value_counts())>th:\n",
    "                    try:\n",
    "                        assert I[n-1]\n",
    "                        I[n]=I[n-1]\n",
    "                    except KeyError:\n",
    "                        I[n]='I'+str(M_counter)\n",
    "                    good_col-=1\n",
    "                else:\n",
    "                    M_counter+=1\n",
    "            except KeyError:\n",
    "                M_counter+=1\n",
    "        return good_col,I\n",
    "    \n",
    "    def transition_matrix(self):\n",
    "        Trans=pd.DataFrame(0,index=self.hmm,columns=self.hmm)\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        #print Trans\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            path=['S']\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        #good_counter+=1\n",
    "                        continue\n",
    "                    else:\n",
    "                        if path[-1][0]=='I':\n",
    "                            path+=[path[-1]]\n",
    "                            #print path,i,good_counter\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                            continue\n",
    "                        else:\n",
    "                            path+=['I'+str(M_counter-1)]\n",
    "                            #print path,i,good_counter\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                            #good_counter+=1\n",
    "                elif seq[i] =='-':\n",
    "                    path+=['D'+str(M_counter)]\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "                else:\n",
    "                    path+=['M'+str(M_counter)]\n",
    "                    #print path,i\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "            path+=['E']\n",
    "            Trans[path[-1]][path[-2]]+=1\n",
    "        for row in Trans.index:\n",
    "             Trans.loc[row]=Trans.loc[row]/Trans.loc[row].sum()\n",
    "        Trans=Trans.fillna(0)\n",
    "        return Trans \n",
    "\n",
    "    def emission_matrix(self):\n",
    "        Em=pd.DataFrame(0,index=self.hmm,columns=self.alph)\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        continue\n",
    "                    else:\n",
    "                        Em[seq[i]][I[i]]+=1\n",
    "                elif seq[i]=='-':\n",
    "                    M_counter+=1\n",
    "                    pass\n",
    "                else:\n",
    "                    Em[seq[i]]['M'+str(M_counter)]+=1\n",
    "                    M_counter+=1\n",
    "        for row in Em.index:\n",
    "             Em.loc[row]=Em.loc[row]/Em.loc[row].sum()\n",
    "        Em=Em.fillna(0)\n",
    "        return Em  \n",
    "        \n",
    "\n",
    "#print HMM(th,alph,aln).find_insertions()\n",
    "\n",
    "print HMM(th,alph,aln).transition_matrix()\n",
    "print '--------'\n",
    "print HMM(th,alph,aln).emission_matrix()\n",
    "\n",
    "HMM(th,alph,aln).transition_matrix().to_csv('output.txt', mode='w', header=True,sep='\\t')\n",
    "with open('output.txt', 'a') as fa:\n",
    "             fa.write('--------'+'\\n')\n",
    "HMM(th,alph,aln).emission_matrix().to_csv('output.txt', mode='a', header=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.399 0.01 ['A B C D E'] [['E', 'D', '-', 'B', 'C', 'B', 'D', 'A', 'C'], ['-', 'D', '-', 'A', 'B', 'B', 'D', 'A', 'C'], ['E', 'D', '-', '-', 'E', 'B', 'D', '-', 'C'], ['-', 'C', '-', 'B', 'C', 'B', '-', 'D', '-'], ['A', 'D', '-', 'B', 'C', '-', 'C', 'A', '-'], ['-', 'D', 'D', 'B', '-', 'B', 'A', '-', 'C']]\n",
      "    S        I0        M1        D1        I1        M2        D2        I2  \\\n",
      "S   0  0.495146  0.495146  0.009709  0.000000  0.000000  0.000000  0.000000   \n",
      "I0  0  0.009709  0.980583  0.009709  0.000000  0.000000  0.000000  0.000000   \n",
      "M1  0  0.000000  0.000000  0.000000  0.171521  0.656958  0.171521  0.000000   \n",
      "D1  0  0.000000  0.000000  0.000000  0.333333  0.333333  0.333333  0.000000   \n",
      "I1  0  0.000000  0.000000  0.000000  0.009709  0.980583  0.009709  0.000000   \n",
      "M2  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.009709   \n",
      "D2  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.009709   \n",
      "I2  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.333333   \n",
      "M3  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "D3  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I3  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "M4  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "D4  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I4  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "M5  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "D5  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I5  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "M6  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "D6  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I6  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "M7  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "D7  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I7  0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "E   0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "          M3        D3    ...           M5        D5        I5        M6  \\\n",
      "S   0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I0  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "M1  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "D1  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I1  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "M2  0.786408  0.203883    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "D2  0.980583  0.009709    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I2  0.333333  0.333333    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "M3  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "D3  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I3  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "M4  0.000000  0.000000    ...     0.786408  0.203883  0.000000  0.000000   \n",
      "D4  0.000000  0.000000    ...     0.980583  0.009709  0.000000  0.000000   \n",
      "I4  0.000000  0.000000    ...     0.333333  0.333333  0.000000  0.000000   \n",
      "M5  0.000000  0.000000    ...     0.000000  0.000000  0.009709  0.592233   \n",
      "D5  0.000000  0.000000    ...     0.000000  0.000000  0.009709  0.980583   \n",
      "I5  0.000000  0.000000    ...     0.000000  0.000000  0.333333  0.333333   \n",
      "M6  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "D6  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I6  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "M7  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "D7  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "I7  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "E   0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "          D6        I6        M7        D7        I7         E  \n",
      "S   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "D1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "D2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "D3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "D4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M5  0.398058  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "D5  0.009709  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "I5  0.333333  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "M6  0.000000  0.009709  0.495146  0.495146  0.000000  0.000000  \n",
      "D6  0.000000  0.009709  0.980583  0.009709  0.000000  0.000000  \n",
      "I6  0.000000  0.333333  0.333333  0.333333  0.000000  0.000000  \n",
      "M7  0.000000  0.000000  0.000000  0.000000  0.009804  0.990196  \n",
      "D7  0.000000  0.000000  0.000000  0.000000  0.009804  0.990196  \n",
      "I7  0.000000  0.000000  0.000000  0.000000  0.500000  0.500000  \n",
      "E   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[24 rows x 24 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'E'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-7362ca8cc771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m              \u001b[0mfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mHMM_pseudo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpseudo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.3f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-220-7362ca8cc771>\u001b[0m in \u001b[0;36memission_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         \u001b[0mEm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mM_counter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juniper_admin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juniper_admin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juniper_admin/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juniper_admin/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juniper_admin/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'E'"
     ]
    }
   ],
   "source": [
    "'''Solve the Profile HMM with Pseudocounts Problem'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#file='input.txt'\n",
    "file='input2.txt'\n",
    "#file='../../Downloads/dataset_11632_4.txt'\n",
    "#file='../../Downloads/rosalind_ba10f.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "print map(str,lines[0].split('\\t'))[-1]\n",
    "th=float(map(str,lines[0].split('\\t'))[0])\n",
    "pseudo=float(map(str,lines[0].split('\\t'))[-1])\n",
    "alph=map(str,lines[2].split('\\t'))\n",
    "aln=[list(line) for line in lines[4:]]\n",
    "print th,pseudo,alph,aln\n",
    "\n",
    "\n",
    "class HMM_pseudo:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    def __init__(self, threshold, pseudo, alphabet, alignment):\n",
    "        self.th = threshold #e.g. 0.301\n",
    "        self.pseudo = pseudo # e.g. 0.01\n",
    "        self.alph = alphabet #e.g. ['A', 'B', 'C', 'D', 'E']\n",
    "        self.aln = alignment #e.g.  [['E', 'B', 'A'], ['E', '-', 'D'], ['E', 'B', '-'], ['E', 'E', 'D'], ['E', 'B', 'D'], ['E', 'B', 'E'], ['E', '-', 'D'], ['E', '-', 'D']]\n",
    "        self.I = self.find_insertions()[1]\n",
    "        self.good_col = self.find_insertions()[0]\n",
    "        self.hmm = ['S','I0']+[St+str(n) for n in range(1,self.good_col+1) for St in ['M','D','I']]+['E']\n",
    "    \n",
    "    def find_insertions(self):\n",
    "        a=pd.DataFrame(self.aln)\n",
    "        I={}\n",
    "        good_col=len(a.columns)\n",
    "        M_counter=0\n",
    "        for n in range(len(a.columns)):\n",
    "            col=n\n",
    "            try:\n",
    "                if float(a[col].value_counts().to_dict()['-'])/sum(a[col].value_counts())>th:\n",
    "                    try:\n",
    "                        assert I[n-1]\n",
    "                        I[n]=I[n-1]\n",
    "                    except KeyError:\n",
    "                        I[n]='I'+str(M_counter)\n",
    "                    good_col-=1\n",
    "                else:\n",
    "                    M_counter+=1\n",
    "            except KeyError:\n",
    "                M_counter+=1\n",
    "        return good_col,I\n",
    "    \n",
    "    def transition_matrix(self):\n",
    "        Trans=pd.DataFrame(0,index=self.hmm,columns=self.hmm)\n",
    "        pseudo=self.pseudo\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        good_col=self.good_col\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            path=['S']\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        continue\n",
    "                    else:\n",
    "                        if path[-1][0]=='I':\n",
    "                            path+=[path[-1]]\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                            continue\n",
    "                        else:\n",
    "                            path+=['I'+str(M_counter-1)]\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                elif seq[i] =='-':\n",
    "                    path+=['D'+str(M_counter)]\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "                else:\n",
    "                    path+=['M'+str(M_counter)]\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "            path+=['E']\n",
    "            Trans[path[-1]][path[-2]]+=1\n",
    "        \n",
    "        ### ger rel, add pseudocounts and get rel ###\n",
    "        ## start\n",
    "        subset=Trans.loc['S':'I0', 'I0':'D1']\n",
    "        for row in subset.index:\n",
    "            subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "            subset.loc[row]=subset.loc[row].fillna(0)\n",
    "            subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+3*pseudo)\n",
    "        Trans.loc['S':'I0', 'I0':'D1']=subset\n",
    "        ## between matches\n",
    "        for n in range(1,good_col):\n",
    "            subset=Trans.loc['M'+str(n):'I'+str(n), 'I'+str(n):'D'+str(n+1)]\n",
    "            for row in subset.index:\n",
    "                subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "                subset.loc[row]=subset.loc[row].fillna(0)\n",
    "                subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+3*pseudo)\n",
    "            Trans.loc['M'+str(n):'I'+str(n), 'I'+str(n):'D'+str(n+1)]=subset\n",
    "        ## end\n",
    "        subset=Trans.loc['M'+str(good_col):'I'+str(good_col), 'I'+str(good_col):'E']\n",
    "        for row in subset.index:\n",
    "            subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "            subset.loc[row]=subset.loc[row].fillna(0)\n",
    "            subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+2*pseudo)\n",
    "        Trans.loc['M'+str(good_col):'I'+str(good_col), 'I'+str(good_col):'E']=subset\n",
    "        return Trans\n",
    "    \n",
    "    def emission_matrix(self):\n",
    "        Em=pd.DataFrame(0,index=self.hmm,columns=self.alph)\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        continue\n",
    "                    else:\n",
    "                        Em[seq[i]][I[i]]+=1\n",
    "                elif seq[i]=='-':\n",
    "                    M_counter+=1\n",
    "                    pass\n",
    "                else:\n",
    "                    Em[seq[i]]['M'+str(M_counter)]+=1\n",
    "                    M_counter+=1\n",
    "        for row in Em.index:\n",
    "            if row[0] in ['S','D','E']:\n",
    "                pass\n",
    "            else:\n",
    "                Em.loc[row]=Em.loc[row]/Em.loc[row].sum()\n",
    "                Em.loc[row]=Em.loc[row].fillna(0)\n",
    "                Em.loc[row]=(Em.loc[row]+pseudo)/(Em.loc[row].sum()+len(self.alph)*pseudo)\n",
    "        return Em  \n",
    "\n",
    "\n",
    "#print HMM(th,alph,aln).find_insertions()\n",
    "\n",
    "print HMM_pseudo(th,pseudo,alph,aln).transition_matrix()\n",
    "#print '--------'\n",
    "#print HMM(th,alph,aln).emission_matrix()\n",
    "\n",
    "HMM_pseudo(th,pseudo,alph,aln).transition_matrix().to_csv('output.txt', mode='w', header=True,sep='\\t',float_format='%.3f')\n",
    "with open('output.txt', 'a') as fa:\n",
    "             fa.write('--------'+'\\n')\n",
    "HMM_pseudo(th,pseudo,alph,aln).emission_matrix().to_csv('output.txt', mode='a', header=True,sep='\\t',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc 8\n",
      "['A', 'E', 'F', 'D', 'F', 'D', 'C']\n",
      "M4 -0.853970820607\n",
      "['M3', [-5.1131282214239588, -0.0085158509225296275, -0.11682084638612046], 'D3', [-0.7286341232984398, -0.0085158509225296275, -0.11682084638612046], 'I3', [-5.2894628054361803, -0.47712125471966238, -0.11682084638612046]]\n",
      "D5 -1.54458875058\n",
      "M5 -0.979307517916\n",
      "['M4', [-0.85397082060708984, -0.10435220582652247, -0.020984491482127662], 'D4', [-3.9967438531069188, -0.47712125471966238, -0.020984491482127662], 'I4', [-3.9967438531069188, -0.47712125471966238, -0.020984491482127662]]\n",
      "D5 -5.37735305552\n",
      "M6 -2.7450116811\n",
      "['M5', [-6.1473864156803391, -0.59786387673435426, -0.703086570530851], 'D5', [-5.3773530555188751, -0.0085158509225296275, -0.703086570530851], 'I5', [-1.814417720870972, -0.2275073896944052, -0.703086570530851]]\n",
      "M1 D2 D3 M4 M5 I5 M6 M7 M8\n"
     ]
    }
   ],
   "source": [
    "'''Solve the Sequence Alignment with Profile HMM Problem'''\n",
    "\n",
    "class HMM_pseudo:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    def __init__(self, threshold, pseudo, alphabet, alignment):\n",
    "        self.th = threshold #e.g. 0.301\n",
    "        self.pseudo = pseudo # e.g. 0.01\n",
    "        self.alph = alphabet #e.g. ['A', 'B', 'C', 'D', 'E']\n",
    "        self.aln = alignment #e.g.  [['E', 'B', 'A'], ['E', '-', 'D'], ['E', 'B', '-'], ['E', 'E', 'D'], ['E', 'B', 'D'], ['E', 'B', 'E'], ['E', '-', 'D'], ['E', '-', 'D']]\n",
    "        self.I = self.find_insertions()[1]\n",
    "        self.good_col = self.find_insertions()[0]\n",
    "        self.hmm = ['S','I0']+[St+str(n) for n in range(1,self.good_col+1) for St in ['M','D','I']]+['E']\n",
    "    \n",
    "    def find_insertions(self):\n",
    "        a=pd.DataFrame(self.aln)\n",
    "        I={}\n",
    "        good_col=len(a.columns)\n",
    "        M_counter=0\n",
    "        for n in range(len(a.columns)):\n",
    "            col=n\n",
    "            try:\n",
    "                if float(a[col].value_counts().to_dict()['-'])/sum(a[col].value_counts())>=th:\n",
    "                    try:\n",
    "                        assert I[n-1]\n",
    "                        I[n]=I[n-1]\n",
    "                    except KeyError:\n",
    "                        I[n]='I'+str(M_counter)\n",
    "                    good_col-=1\n",
    "                else:\n",
    "                    M_counter+=1\n",
    "            except KeyError:\n",
    "                M_counter+=1\n",
    "        return good_col,I\n",
    "    \n",
    "    def transition_matrix(self):\n",
    "        Trans=pd.DataFrame(0,index=self.hmm,columns=self.hmm)\n",
    "        pseudo=self.pseudo\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        good_col=self.good_col\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            path=['S']\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        continue\n",
    "                    else:\n",
    "                        if path[-1][0]=='I':\n",
    "                            path+=[path[-1]]\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                            continue\n",
    "                        else:\n",
    "                            path+=['I'+str(M_counter-1)]\n",
    "                            Trans[path[-1]][path[-2]]+=1\n",
    "                elif seq[i] =='-':\n",
    "                    path+=['D'+str(M_counter)]\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "                else:\n",
    "                    path+=['M'+str(M_counter)]\n",
    "                    Trans[path[-1]][path[-2]]+=1\n",
    "                    M_counter+=1\n",
    "            path+=['E']\n",
    "            Trans[path[-1]][path[-2]]+=1\n",
    "        \n",
    "        ### ger rel, add pseudocounts and get rel ###\n",
    "        ## start\n",
    "        subset=Trans.loc['S':'I0', 'I0':'D1']\n",
    "        for row in subset.index:\n",
    "            subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "            subset.loc[row]=subset.loc[row].fillna(0)\n",
    "            subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+3*pseudo)\n",
    "        Trans.loc['S':'I0', 'I0':'D1']=subset\n",
    "        ## between matches\n",
    "        for n in range(1,good_col):\n",
    "            subset=Trans.loc['M'+str(n):'I'+str(n), 'I'+str(n):'D'+str(n+1)]\n",
    "            for row in subset.index:\n",
    "                subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "                #print 'subset.loc[row]', row\n",
    "                #print subset.loc[row]\n",
    "                subset.loc[row]=subset.loc[row].fillna(0)\n",
    "                subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+3*pseudo)\n",
    "            Trans.loc['M'+str(n):'I'+str(n), 'I'+str(n):'D'+str(n+1)]=subset\n",
    "        ## end\n",
    "        subset=Trans.loc['M'+str(good_col):'I'+str(good_col), 'I'+str(good_col):'E']\n",
    "        for row in subset.index:\n",
    "            subset.loc[row]=subset.loc[row]/subset.loc[row].sum()\n",
    "            subset.loc[row]=subset.loc[row].fillna(0)\n",
    "            subset.loc[row]=(subset.loc[row]+pseudo)/(subset.loc[row].sum()+2*pseudo)\n",
    "        Trans.loc['M'+str(good_col):'I'+str(good_col), 'I'+str(good_col):'E']=subset\n",
    "        return Trans\n",
    "    \n",
    "    def emission_matrix(self):\n",
    "        Em=pd.DataFrame(0,index=self.hmm,columns=self.alph)\n",
    "        I=self.I\n",
    "        aln=self.aln\n",
    "        for n in range(len(aln)):\n",
    "            seq=aln[n]\n",
    "            M_counter=1\n",
    "            for i in range(len(seq)):\n",
    "                if i in I.keys():\n",
    "                    if seq[i]=='-':\n",
    "                        continue\n",
    "                    else:\n",
    "                        Em[seq[i]][I[i]]+=1\n",
    "                elif seq[i]=='-':\n",
    "                    M_counter+=1\n",
    "                    pass\n",
    "                else:\n",
    "                    Em[seq[i]]['M'+str(M_counter)]+=1\n",
    "                    M_counter+=1\n",
    "        for row in Em.index:\n",
    "            if row[0] in ['S','D','E']:\n",
    "                pass\n",
    "            else:\n",
    "                Em.loc[row]=Em.loc[row]/Em.loc[row].sum()\n",
    "                Em.loc[row]=Em.loc[row].fillna(0)\n",
    "                Em.loc[row]=(Em.loc[row]+pseudo)/(Em.loc[row].sum()+len(self.alph)*pseudo)\n",
    "        return Em\n",
    "    \n",
    "    #HMM_pseudo(th,pseudo,alph,aln).transition_matrix().to_csv('output.txt', mode='w', header=True,sep='\\t')\n",
    "    def Align_to_HMMprofile(self,x):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        #x=self.x\n",
    "        gc=self.good_col\n",
    "        Trans=HMM_pseudo(self.th,self.pseudo,self.alph,self.aln).transition_matrix()\n",
    "        Trans=np.log10(Trans)\n",
    "\n",
    "        Em=HMM_pseudo(self.th,self.pseudo,self.alph,self.aln).emission_matrix()\n",
    "        Em=np.log10(Em)\n",
    "        hmm=self.hmm\n",
    "\n",
    "        V=pd.DataFrame(-float('Inf'),index=hmm[1:-1],columns=range(len(x)))\n",
    "        Backtrack=pd.DataFrame(list,index=hmm[1:-1],columns=range(len(x)))\n",
    "        Index=['S']+['D'+str(n+1) for n in range(gc)]\n",
    "        sdic={}\n",
    "        Silent={} #Score for 0th column that contains only silent states\n",
    "        Silent['S']=0\n",
    "        for n in range(len(Index)):\n",
    "            sdic[n]=Index[n]\n",
    "            if n>0:\n",
    "                Silent[Index[n]]=Silent[Index[n-1]]+Trans[Index[n]][Index[n-1]]\n",
    "        ### Fill first column of Viterbi graph\n",
    "        for node in V.index:\n",
    "            idx=int(node[1:])\n",
    "            if node[0]=='D':\n",
    "                if node=='D1':\n",
    "                    V[0][node]=V[0]['I0']+Trans[node]['I0']\n",
    "                    Backtrack[0][node]=[-1,'I0']\n",
    "                else:\n",
    "                    V[0][node]=max([V[0][ST+str(idx-1)]+Trans[node][ST+str(idx-1)] for ST in ['M','D','I']])\n",
    "                    Backtrack[0][node]=[0,[ST+str(idx-1) for ST in ['M','D','I'] if V[0][node]==V[0][ST+str(idx-1)]+Trans[node][ST+str(idx-1)]][0]]\n",
    "            elif node=='I0':\n",
    "                V[0][node]=Silent['S']+Trans[node]['S']+Em[x[0]][node]\n",
    "                Backtrack[0][node]=[-1,'S']\n",
    "            else:\n",
    "                V[0][node]=Silent[sdic[idx-1]]+Trans[node][sdic[idx-1]]+Em[x[0]][node]\n",
    "                Backtrack[0][node]=[-1,sdic[idx-1]]\n",
    "\n",
    "        ### Fill all following columns of Viterbi graph\n",
    "        for n in V.columns[1:]:\n",
    "            for node in V.index:\n",
    "                idx=int(node[1:])\n",
    "                if node=='I0':\n",
    "                    V[n][node]=V[n-1][node]+Trans[node][node]+Em[x[n]][node]\n",
    "                    Backtrack[n][node]=[int(n-1),node]\n",
    "                elif node=='M1':\n",
    "                    V[n][node]=V[n-1]['I0']+Trans[node]['I0']+Em[x[n]][node]\n",
    "                    Backtrack[n][node]=[n-1,'I0']\n",
    "                elif node=='D1':\n",
    "                    V[n][node]=V[n]['I0']+Trans[node]['I0']\n",
    "                    Backtrack[n][node]=[n,'I0']\n",
    "                elif node[0]=='I':\n",
    "                    V[n][node]=max([V[n-1][ST+str(idx)]+Trans[node][ST+str(idx)]+Em[x[n]][node] for ST in ['M','D','I']])\n",
    "                    Backtrack[n][node]=[n-1,[ST+str(idx) for ST in ['M','D','I'] if V[n][node]==V[n-1][ST+str(idx)]+Trans[node][ST+str(idx)]+Em[x[n]][node]][0]]\n",
    "                elif node[0]=='M':\n",
    "                    V[n][node]=max([V[n-1][ST+str(idx-1)]+Trans[node][ST+str(idx-1)]+Em[x[n]][node] for ST in ['M','D','I']])\n",
    "                    Backtrack[n][node]=[n-1,[ST+str(idx-1) for ST in ['M','D','I'] if V[n][node]==V[n-1][ST+str(idx-1)]+Trans[node][ST+str(idx-1)]+Em[x[n]][node]][0]]\n",
    "                elif node[0]=='D':\n",
    "                    V[n][node]=max([V[n][ST+str(idx-1)]+Trans[node][ST+str(idx-1)] for ST in ['M','D','I']])\n",
    "                    Backtrack[n][node]=[n,[ST+str(idx-1) for ST in ['M','D','I'] if V[n][node]==V[n][ST+str(idx-1)]+Trans[node][ST+str(idx-1)]][0]]\n",
    "\n",
    "        ### Backtrack\n",
    "        result=[]\n",
    "        maxscore=max([V[n][ST]+Trans['E'][ST] for ST in V.index[-3:]])\n",
    "        node=[ST for ST in V.index[-3:] if V[n][ST]+Trans['E'][ST]==maxscore][0]\n",
    "        while True:\n",
    "            prevnode=Backtrack[n][node][1]\n",
    "            prevcol=Backtrack[n][node][0]\n",
    "            result+=[node]\n",
    "            node=prevnode\n",
    "            n=prevcol\n",
    "            if node in ['I0','S']:\n",
    "                break\n",
    "        return result[::-1]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#file='input.txt'\n",
    "#file='input2.txt'\n",
    "#file='../../Downloads/dataset_11632_6.txt'\n",
    "file='../../Downloads/rosalind_ba10g.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "x=list(lines[0])\n",
    "th=float(map(str,lines[2].split(' '))[0])\n",
    "pseudo=float(map(str,lines[2].split(' '))[-1])\n",
    "alph=map(str,lines[4].split(' '))\n",
    "aln=[list(line) for line in lines[6:]]\n",
    "\n",
    "#print th,pseudo,alph,aln\n",
    "print ' '.join(HMM_pseudo(th,pseudo,alph,aln).Align_to_HMMprofile(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z', 'x', 'z', 'y', 'z', 'z', 'y', 'z', 'y', 'x', 'y', 'x', 'z', 'x', 'z', 'y', 'y', 'y', 'x', 'x', 'z', 'y', 'x', 'x', 'z', 'y', 'x', 'y', 'y', 'y', 'x', 'y', 'z', 'x', 'y', 'y', 'x', 'z', 'z', 'x', 'x', 'x', 'z', 'z', 'y', 'y', 'y', 'y', 'z', 'x', 'z', 'x', 'z', 'z', 'x', 'x', 'y', 'z', 'x', 'z', 'y', 'x', 'y', 'z', 'y', 'x', 'z', 'y', 'x', 'z', 'y', 'x', 'x', 'z', 'x', 'y', 'y', 'z', 'z', 'x', 'y', 'z', 'x', 'x', 'z', 'z', 'x', 'y', 'y', 'z', 'x', 'x', 'y', 'y', 'y', 'z', 'y', 'x', 'x', 'x'] ['x', 'y', 'z'] CACBBDCBBBBDCCBCCABDCDCAACDACDBCBDCABCBDDABDDACADCDDBACADBDBDBDACBADADDDDACCDCAADDAACCDCCBBBBDABBCCB ['A', 'B', 'C', 'D']\n",
      "\n",
      "            A          B          C          D\n",
      "A        0.15        0.2        0.4       0.25\n",
      "B  0.08333333  0.3333333  0.1666667  0.4166667\n",
      "C   0.2592593  0.2962963  0.2222222  0.2222222\n",
      "D   0.2857143  0.1785714  0.2857143       0.25\n",
      "--------\n",
      "           x          y          z\n",
      "A        0.4        0.3        0.3\n",
      "B       0.36        0.2       0.44\n",
      "C  0.2592593  0.4444444  0.2962963\n",
      "D  0.3928571  0.3928571  0.2142857\n"
     ]
    }
   ],
   "source": [
    "''' Solve the HMM Parameter Estimation Problem'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "file='input.txt'\n",
    "file='input2.txt'\n",
    "file='../../Downloads/dataset_11632_8.txt'\n",
    "file='../../Downloads/rosalind_ba10h.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "x=list(lines[0])\n",
    "alph=map(str,lines[2].split('\\t'))\n",
    "Pi=lines[4]\n",
    "states=map(str,lines[6].split('\\t'))\n",
    "\n",
    "print x,alph,Pi,states\n",
    "print\n",
    "\n",
    "def ParameterEstimation(x,alph,Pi,states)\n",
    "    Trans=pd.DataFrame(float,columns=states,index=states)\n",
    "    for combi in itertools.product(states, repeat=2):\n",
    "        row=combi[0]\n",
    "        col=combi[1]\n",
    "        if row not in Pi:\n",
    "            Trans[col][row]=1./len(states)\n",
    "        else:\n",
    "            #print row,col,float(Pi.count(row+col)),Pi[:-1].count(row), len(re.findall('(?='+row+col+')', Pi))\n",
    "            Trans[col][row]=float(len(re.findall('(?='+row+col+')', Pi)))/Pi[:-1].count(row)\n",
    "    Em=pd.DataFrame(float,columns=alph,index=states)\n",
    "    for combi in itertools.product(states,alph):\n",
    "        row=combi[0]\n",
    "        col=combi[1]\n",
    "        if row not in Pi:\n",
    "            Em[col][row]=1./len(states)\n",
    "        else:\n",
    "            Em[col][row]=float(zip(Pi,x).count((row,col)))/Pi.count(row)\n",
    "    return Trans,Em    \n",
    "\n",
    "Trans,Em=ParameterEstimation(x,alph,Pi,states)\n",
    "Trans.to_csv('output.txt', mode='w', header=True,sep='\\t',float_format='%.3f')\n",
    "with open('output.txt', 'a') as fa:\n",
    "             fa.write('--------'+'\\n')\n",
    "Em.to_csv('output.txt', mode='a', header=True,sep='\\t',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j= 100\n",
      "x= ['z', 'y', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'z']\n",
      "alph= ['x', 'y', 'z']\n",
      "states= ['A', 'B']\n",
      "       x      y      z\n",
      "A  0.424  0.367  0.209\n",
      "B  0.262  0.449  0.289\n",
      "       A      B\n",
      "A  0.599  0.401\n",
      "B  0.294  0.706\n",
      "<module 'numpy' from '/Users/juniper_admin/anaconda/lib/python2.7/site-packages/numpy/__init__.pyc'>\n",
      "Pi= BBBBBBBBBB\n",
      "<module 'numpy' from '/Users/juniper_admin/anaconda/lib/python2.7/site-packages/numpy/__init__.pyc'>\n",
      "Pi= BBBBBBBBBB\n",
      "     A    B\n",
      "A  0.5  0.5\n",
      "B  0.0  1.0\n",
      "--------\n",
      "          x         y         z\n",
      "A  0.333333  0.333333  0.333333\n",
      "B  0.400000  0.100000  0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juniper_admin/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:129: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "/Users/juniper_admin/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:130: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "/Users/juniper_admin/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:45: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "'''Implement Viterbi learning for estimating the parameters of an HMM'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ViterbiLearning(x,alph,states,Trans,Em):\n",
    "    \n",
    "    '''Returns the emission and transition matrices resulting from applying Viterbi learning for j iterations.\n",
    "    INPUT:\n",
    "    j= 100\n",
    "    x= ['z', 'y', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'z']\n",
    "    alph= ['x', 'y', 'z']\n",
    "    states= ['A', 'B']\n",
    "    OUPUT:\n",
    "    Trans=     A    B # pandas table\n",
    "        A  0.5  0.5\n",
    "        B    0    1\n",
    "    Em=          x         y         z # pandas table\n",
    "        A  0.333333  0.333333  0.333333\n",
    "        B       0.4       0.1       0.5\n",
    "    '''\n",
    "    \n",
    "    def FindJiddenPath(x,alp,st,Trans,Em):\n",
    "        import numpy as np\n",
    "        '''\n",
    "        Finds a path that maximizes the (unconditional) probability Pr(x, Pi) over all possible paths Pi\n",
    "        Input:\n",
    "        x= ['z', 'y', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'z']\n",
    "        alp= ['x', 'y', 'z']\n",
    "        st= ['A', 'B']\n",
    "        Trans=     A    B # pandas table\n",
    "        A  0.5  0.5\n",
    "        B    0    1\n",
    "        Em=          x         y         z # pandas table\n",
    "            A  0.333333  0.333333  0.333333\n",
    "            B       0.4       0.1       0.5\n",
    "        OUTPUT=BBBBBBBBBB\n",
    "        '''\n",
    "        Trans=np.log10(Trans)\n",
    "        Em=np.log10(Em)\n",
    "        Pi={}\n",
    "        Backtrack={}\n",
    "        Pi[0]={}\n",
    "        [Pi[0].update({st[n]:np.log10(0.5)+Em[x[0]][st[n]]}) for n in range(len(st))]\n",
    "        for n in range(1,len(x)):\n",
    "            Pi[n]={}\n",
    "            [Pi[n].update({st[i]:max([Pi[n-1][st[j]]+Em[x[n]][st[i]]+Trans[st[i]][st[j]] for j in range(len(st))])})\\\n",
    "                           for i in range(len(st))]\n",
    "            Backtrack[n]={}\n",
    "            for i in range(len(st)):\n",
    "                for j in range(len(st)):\n",
    "                    if Pi[n-1][st[j]]+Em[x[n]][st[i]]+Trans[st[i]][st[j]] == Pi[n][st[i]]:\n",
    "                        Backtrack[n].update({st[i]:st[j]})\n",
    "        pi_string=[]\n",
    "        good_state=[k for k,v in Pi[len(x)-1].items() if v==max(Pi[len(x)-1].values())][0]\n",
    "        pi_string=good_state\n",
    "        for n in reversed(range(1,len(x))):\n",
    "            new_state=Backtrack[n][good_state]\n",
    "            pi_string+=new_state\n",
    "            good_state=new_state\n",
    "        return pi_string[::-1]\n",
    "\n",
    "    def ParameterEstimation(x,alph,Pi,states):\n",
    "        '''\n",
    "        Find optimal parameters explaining the emitted string and hidden path of an HMM\n",
    "        INPUT:\n",
    "        x= ['z', 'y', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'z']\n",
    "        alph= ['x', 'y', 'z']\n",
    "        Pi= BBBBBBBBBB\n",
    "        states= ['A', 'B']\n",
    "\n",
    "        OUTPUT:\n",
    "        Trans=     A    B # pandas table\n",
    "            A  0.5  0.5\n",
    "            B    0    1\n",
    "        Em=          x         y         z # pandas table\n",
    "            A  0.333333  0.333333  0.333333\n",
    "            B       0.4       0.1       0.5\n",
    "        '''\n",
    "        Trans=pd.DataFrame(-float('Inf'),columns=states,index=states)\n",
    "        for combi in itertools.product(states, repeat=2):\n",
    "            row=combi[0]\n",
    "            col=combi[1]\n",
    "            if row not in Pi:\n",
    "                Trans[col][row]=1./len(states)\n",
    "            else:\n",
    "                Trans[col][row]=float(len(re.findall('(?='+row+col+')', Pi)))/Pi[:-1].count(row)\n",
    "        Em=pd.DataFrame(-float('Inf'),columns=alph,index=states)\n",
    "        for combi in itertools.product(states,alph):\n",
    "            row=combi[0]\n",
    "            col=combi[1]\n",
    "            if row not in Pi:\n",
    "                Em[col][row]=1./len(alph)\n",
    "            else:\n",
    "                Em[col][row]=float(zip(Pi,x).count((row,col)))/Pi.count(row)\n",
    "        return Trans,Em    \n",
    "\n",
    "    ##########################################\n",
    "    n=0\n",
    "    while n<=1:\n",
    "        Pi=FindJiddenPath(x,alph,states,Trans,Em)\n",
    "        print 'Pi=',Pi\n",
    "        Trans,Em=ParameterEstimation(x,alph,Pi,states)\n",
    "        n+=1\n",
    "    return Trans,Em\n",
    "\n",
    "\n",
    "\n",
    "#file='input.txt'\n",
    "file='input2.txt'\n",
    "#file='../../Downloads/dataset_11632_10.txt'\n",
    "#file='../../Downloads/rosalind_ba10i.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "j=int(lines[0])\n",
    "x=list(lines[2])\n",
    "alph=map(str,lines[4].split(' '))\n",
    "states=map(str,lines[6].split(' '))\n",
    "#print lines[8:]\n",
    "footer=[len(lines)-n for n in reversed(range(len(lines))) if lines[n][0]=='-'][0]\n",
    "Trans=pd.read_csv(file, skiprows=8,sep='\\t+',header=0,index_col=0,skipfooter=footer)\n",
    "Em=pd.read_csv(file, skiprows=len(lines)-footer+1,sep='\\t+',header=0,index_col=0)\n",
    "print 'j=',j\n",
    "print 'x=',x\n",
    "print 'alph=',alph\n",
    "print 'states=',states\n",
    "\n",
    "\n",
    "print Em\n",
    "#print Em['A']['A']\n",
    "print Trans\n",
    "#print Em.columns\n",
    "\n",
    "Trans,Em=ViterbiLearning(x,alph,states,Trans,Em)\n",
    "print Trans\n",
    "print '--------'\n",
    "print Em\n",
    "\n",
    "Trans.to_csv('output.txt', mode='w', header=True,sep='\\t',float_format='%.3f')\n",
    "with open('output.txt', 'a') as fa:\n",
    "             fa.write('--------'+'\\n')\n",
    "Em.to_csv('output.txt', mode='a', header=True,sep='\\t',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= ['z', 'y', 'x', 'x', 'x', 'x', 'y', 'x', 'z', 'z']\n",
      "alph= ['x', 'y', 'z']\n",
      "states= ['A', 'B']\n",
      "       x      y      z\n",
      "A  0.356  0.191  0.453\n",
      "B  0.040  0.467  0.493\n",
      "       A      B\n",
      "A  0.911  0.089\n",
      "B  0.228  0.772\n",
      "4.19031553963e-06\n",
      "1.01538360912e-05\n",
      "2.46044447947e-05\n",
      "7.58656520021e-05\n",
      "0.000436006988477\n",
      "0.00134438938713\n",
      "0.00414530700654\n",
      "0.0127816913336\n",
      "0.0394112265\n",
      "{0: {'A': -0.64493179365114939}, 1: {'A': -0.40438004943042344}, 2: {'A': 0.10658832551545008}, 3: {'A': 0.6175567004613236}, 4: {'A': 1.1285250754071972}, 5: {'A': 1.6394934503530709}, 6: {'A': 1.8800451945737966}, 7: {'A': 2.3910135695196701}, 8: {'A': 3.0066301485055003}, 9: {'A': 3.6222467274913304}}\n",
      "4190.31553963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juniper_admin/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:60: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "/Users/juniper_admin/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:61: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "'''Solve the Soft Decoding Problem.'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def FindJiddenPath(x,alp,st,Trans,Em):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Finds a path that maximizes the (unconditional) probability Pr(x, Pi) over all possible paths Pi\n",
    "    Input:\n",
    "    x= ['z', 'y', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'z']\n",
    "    alp= ['x', 'y', 'z']\n",
    "    st= ['A', 'B']\n",
    "    Trans=     A    B # pandas table\n",
    "    A  0.5  0.5\n",
    "    B    0    1\n",
    "    Em=          x         y         z # pandas table\n",
    "        A  0.333333  0.333333  0.333333\n",
    "        B       0.4       0.1       0.5\n",
    "    OUTPUT=BBBBBBBBBB\n",
    "    '''\n",
    "    Trans=np.log10(Trans)\n",
    "    Em=np.log10(Em)\n",
    "    Pi={}\n",
    "    Backtrack={}\n",
    "    Pi[0]={}\n",
    "    [Pi[0].update({st[n]:np.log10(0.5)+Em[x[0]][st[n]]}) for n in range(len(st))]\n",
    "    for n in range(1,len(x)):\n",
    "        Pi[n]={}\n",
    "        [Pi[n].update({st[i]:max([Pi[n-1][st[j]]+Em[x[n]][st[i]]+Trans[st[i]][st[j]] for j in range(len(st))])})\\\n",
    "                       for i in range(len(st))]\n",
    "        Backtrack[n]={}\n",
    "        for i in range(len(st)):\n",
    "            for j in range(len(st)):\n",
    "                if Pi[n-1][st[j]]+Em[x[n]][st[i]]+Trans[st[i]][st[j]] == Pi[n][st[i]]:\n",
    "                    Backtrack[n].update({st[i]:st[j]})\n",
    "    pi_string=[]\n",
    "    good_state=[k for k,v in Pi[len(x)-1].items() if v==max(Pi[len(x)-1].values())][0]\n",
    "    pi_string=good_state\n",
    "    for n in reversed(range(1,len(x))):\n",
    "        print 10**Pi[n][good_state]\n",
    "        new_state=Backtrack[n][good_state]\n",
    "        pi_string+=new_state\n",
    "        good_state=new_state\n",
    "    return pi_string[::-1]\n",
    "\n",
    "file='input.txt'\n",
    "#file='input2.txt'\n",
    "#file='../../Downloads/dataset_11632_10.txt'\n",
    "#file='../../Downloads/rosalind_ba10i.txt'\n",
    "\n",
    "f=open(file,'r')\n",
    "lines=f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "x=list(lines[0])\n",
    "alph=map(str,lines[2].split('\\t'))\n",
    "states=map(str,lines[4].split('\\t'))\n",
    "#print lines[8:]\n",
    "footer=[len(lines)-n for n in reversed(range(len(lines))) if lines[n][0]=='-'][0]\n",
    "Trans=pd.read_csv(file, skiprows=6,sep='\\t+',header=0,index_col=0,skipfooter=footer)\n",
    "Em=pd.read_csv(file, skiprows=len(lines)-footer+1,sep='\\t+',header=0,index_col=0)\n",
    "print 'x=',x\n",
    "print 'alph=',alph\n",
    "print 'states=',states\n",
    "\n",
    "print Em\n",
    "#print Em['A']['A']\n",
    "print Trans\n",
    "\n",
    "st= FindJiddenPath(x,alph,states,Trans,Em)\n",
    "Em=np.log10(Em)\n",
    "Trans=np.log10(Trans)\n",
    "\n",
    "Fw={}\n",
    "\n",
    "Fw[0]={}\n",
    "[Fw[0].update({st[n]:np.log10(0.5)+Em[x[0]][st[n]]}) for n in range(len(st))]\n",
    "\n",
    "\n",
    "for n in range(1,len(x)):\n",
    "    Fw[n]={}\n",
    "    [Fw[n].update({st[i]:np.log10(sum([10**(Fw[n-1][st[j]]+Em[x[n]][st[i]]+Trans[st[i]][st[j]]) for j in range(len(st))]))})\\\n",
    "                   for i in range(len(st))]\n",
    "print Fw\n",
    "Prx=sum([10**val for val in Fw[len(x)-1].values()])\n",
    "print Prx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Implement Baum-Welch Learning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Implement Baum-Welch Learning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
